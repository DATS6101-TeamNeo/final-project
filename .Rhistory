test_data <- work_df[(train_index + 1):nrow(work_df), ]
# Train the linear regression model
lm_model <- lm(Close ~ lag1 + lag2 + lag3 + lag4 + lag5 + lag6 + lag7, data = train_data)
future_data <- test_data
future_data[, 3:ncol(future_data)] <- 0
future_data[1, 3:ncol(future_data)] <- rev(tail(train_data$Close, 7))
# Make predictions on test data
for (i in 1:nrow(future_data)) {
future_data$Close[i] <- predict(lm_model, newdata = future_data[i, ])
if (i < nrow(future_data)){
future_data[i + 1, 3:ncol(future_data)] <- c(future_data$Close[i], future_data[i, 3:(ncol(future_data) - 1)])
}
}
predictions <- future_data$Close
# Evaluate the model
errors <- predictions - test_data$Close
mae <- mean(abs(errors))
mse <- mean(errors^2)
rmse <- sqrt(mse)
# Print evaluation metrics
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
train_df <- data.frame(Date = work_df[1:train_index, "Date"], Value = coredata(work_df[1:train_index, "Close"]), Type = "Train data")
test_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(work_df[(train_index+1):nrow(work_df), "Close"]), Type = "Test data")
forecast_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(predictions), Type = "Forecast")
# Combine the data frames
combined_df <- rbind(train_df[train_df$Date > plot_start_date, ], test_df, forecast_df)
# Create the plot
ggplot(combined_df, aes(x = Date, y = Value, color = Type, linetype = Type)) +
geom_line() +
labs(title = "Train, Test, and Forecast Data Plot",
x = "Date",
y = "Closing Price") +
scale_color_manual(values = c("red", "orange", "blue")) +
scale_linetype_manual(values = c("dashed", "solid", "solid")) +
theme_minimal() +
theme(legend.position = "right")
combined_df
# Load all required packagess
library(xts)
library(ezids)
library(dplyr)
library(tseries)
library(ggplot2)
library(forecast)
library(corrplot)
library(lubridate)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3)
df <- data.frame(read.csv('https://raw.githubusercontent.com/DATS6101-TeamNeo/datasets/main/dataset2003-2023.csv'))
df$Date <- as.Date(df$Date)
str(df)
work_df <- subset(df, select = -c(6))
str(work_df)
summary(work_df)
work_df$daily_change <- (work_df$Close / lag(work_df$Close) - 1) * 100
head(work_df)
work_df <- na.omit(work_df)
head(work_df)
adf.test(work_df$Close)
# Check the stationarity using the ACF and PACF plots.
acf(work_df$Close, main = "ACF Plot")
pacf(work_df$Close, main = "PACF Plot")
ts_data <- xts(work_df$Close, order.by = work_df$Date)
adf.test(ts_data)
diff_ts_data <- diff(ts_data, differences = 1)
diff_ts_data <- na.omit(diff_ts_data)
adf.test(diff_ts_data)
acf(diff_ts_data, main = "ACF Plot")
pacf(diff_ts_data, main = "PACF Plot")
train_data <- head(diff_ts_data, n = round(0.98 * length(diff_ts_data)))
test_data <- diff_ts_data[-seq_along(train_data)]
arima_model <- auto.arima(train_data)
summary(arima_model)
forecasts <- forecast(arima_model, h = length(test_data))
# Convert the forecasts to the original scale.
last_train_date <- index(tail(train_data, 1))
last_observed_value <- ts_data[last_train_date]
actual_preds <- as.vector(last_observed_value) + cumsum(forecasts$mean)
actual_test <- as.vector(last_observed_value) + cumsum(test_data)
actual_preds <- xts(actual_preds, order.by = index(actual_test))
# Compute the forecasting errors
errors <- actual_preds - actual_test
# Calculate evaluation metrics
mae <- mean(abs(errors))
mse <- mean(errors^2)
rmse <- sqrt(mse)
# Print the evaluation metrics
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
plot(ts_data[index(ts_data) <= last_train_date], type = "l", xlab = "Time", ylab = "Index closing price", main = "Train Data")
plot(ts_data[index(ts_data) > last_train_date], type = "l", xlab = "Time", ylab = "Index closing price", main = "Test Data")
plot_start_date <- as.Date("2023-01-01")
actual_train <- ts_data[index(ts_data) > plot_start_date & index(ts_data) <= last_train_date]
# Convert the time series data to data frames
train_df <- data.frame(Date = index(actual_train), Value = coredata(actual_train), Type = "Train data")
test_df <- data.frame(Date = index(actual_test), Value = coredata(actual_test), Type = "Test data")
forecast_df <- data.frame(Date = index(actual_preds)[-1], Value = actual_preds[-1], Type = "Forecast")
# Combine the data frames
combined_df <- rbind(train_df, test_df, forecast_df)
# Create the plot
ggplot(combined_df, aes(x = Date, y = Value, color = Type, linetype = Type)) +
geom_line() +
labs(title = "Train, Test, and Forecast Data Plot",
x = "Date",
y = "Closing Price") +
scale_color_manual(values = c("red", "orange", "blue")) +
scale_linetype_manual(values = c("dashed", "solid", "solid")) +
theme_minimal() +
theme(legend.position = "right")
# Linear Regression.
# Assuming 'work_df' contains your preprocessed dataset
# You may need to select appropriate features and split the data into train and test sets
work_df <- data.frame(subset(df, select = c(1, 5)))
# Feature selection (Example: using lagged values as features)
for (i in 1:7) {
work_df[[paste0('lag', i)]] <- lag(work_df$Close, i)
}
work_df <- na.omit(work_df)
# Split data into train and test sets
train_size <- 0.98
train_index <- round(nrow(work_df) * train_size)
train_data <- work_df[1:train_index, ]
test_data <- work_df[(train_index + 1):nrow(work_df), ]
# Train the linear regression model
lm_model <- lm(Close ~ lag1 + lag2 + lag3 + lag4 + lag5 + lag6 + lag7, data = train_data)
future_data <- test_data
future_data[, 3:ncol(future_data)] <- 0
future_data[1, 3:ncol(future_data)] <- rev(tail(train_data$Close, 7))
# Make predictions on test data
for (i in 1:nrow(future_data)) {
future_data$Close[i] <- predict(lm_model, newdata = future_data[i, ])
if (i < nrow(future_data)){
future_data[i + 1, 3:ncol(future_data)] <- c(future_data$Close[i], future_data[i, 3:(ncol(future_data) - 1)])
}
}
predictions <- future_data$Close
# Evaluate the model
errors <- predictions - test_data$Close
mae <- mean(abs(errors))
mse <- mean(errors^2)
rmse <- sqrt(mse)
# Print evaluation metrics
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
train_df <- data.frame(Date = work_df[1:train_index, "Date"], Value = coredata(work_df[1:train_index, "Close"]), Type = "Train data")
test_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(work_df[(train_index+1):nrow(work_df), "Close"]), Type = "Test data")
forecast_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(predictions), Type = "Forecast")
# Combine the data frames
combined_df <- rbind(train_df[train_df$Date > plot_start_date, ], test_df, forecast_df)
# Create the plot
ggplot(combined_df, aes(x = Date, y = Value, color = Type, linetype = Type)) +
geom_line() +
labs(title = "Train, Test, and Forecast Data Plot",
x = "Date",
y = "Closing Price") +
scale_color_manual(values = c("red", "orange", "blue")) +
scale_linetype_manual(values = c("dashed", "solid", "solid")) +
theme_minimal() +
theme(legend.position = "right")
ggplot(combined_df, aes(x = Date, y = Value, color = Type, linetype = Type)) +
geom_line() +
labs(title = "Train, Test, and Forecast Data Plot",
x = "Date",
y = "Closing Price") +
scale_color_manual(values = c("red", "orange", "blue")) +
scale_linetype_manual(values = c("solid", "solid", "solid")) +
theme_minimal() +
theme(legend.position = "right")
head(work_df)
head(work_df)
work_df <- data.frame(subset(df, select = c(1, 5)))
# Feature selection (Example: using lagged values as features)
for (i in 1:7) {
work_df[[paste0('lag', i)]] <- lag(work_df$Close, i)
}
work_df <- na.omit(work_df)
# Split data into train and test sets
train_size <- 0.98
train_index <- round(nrow(work_df) * train_size)
train_data <- work_df[1:train_index, ]
test_data <- work_df[(train_index + 1):nrow(work_df), ]
# Train the linear regression model
lm_model <- lm(Close ~ lag1 + lag2 + lag3 + lag4 + lag5 + lag6 + lag7, data = train_data)
future_data <- test_data
future_data[, 3:ncol(future_data)] <- 0
future_data[1, 3:ncol(future_data)] <- rev(tail(train_data$Close, 7))
# Make predictions on test data
for (i in 1:nrow(future_data)) {
future_data$Close[i] <- predict(lm_model, newdata = future_data[i, ])
if (i < nrow(future_data)){
future_data[i + 1, 3:ncol(future_data)] <- c(future_data$Close[i], future_data[i, 3:(ncol(future_data) - 1)])
}
}
predictions <- future_data$Close
# Evaluate the model
errors <- predictions - test_data$Close
mae <- mean(abs(errors))
mse <- mean(errors^2)
rmse <- sqrt(mse)
# Print evaluation metrics
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
```{r, include=T, results=T}
train_df <- data.frame(Date = work_df[1:train_index, "Date"], Value = coredata(work_df[1:train_index, "Close"]), Type = "Train data")
test_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(work_df[(train_index+1):nrow(work_df), "Close"]), Type = "Test data")
forecast_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(predictions), Type = "Forecast")
# Combine the data frames
combined_df <- rbind(train_df[train_df$Date > plot_start_date, ], test_df, forecast_df)
# Create the plot
ggplot(combined_df, aes(x = Date, y = Value, color = Type, linetype = Type)) +
geom_line() +
labs(title = "Train, Test, and Forecast Data Plot",
x = "Date",
y = "Closing Price") +
scale_color_manual(values = c("red", "orange", "blue")) +
scale_linetype_manual(values = c("dashed", "solid", "solid")) +
theme_minimal() +
theme(legend.position = "right")
# Load all required packagess
library(dplyr)
library(ggplot2)
library(ezids)
library(lubridate)
library(corrplot)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3)
library(rvest)
library(tidyverse)
library(quantmod)
library(xts)
library(rvest)
library(dplyr)
library(ezids)
library(ggplot2)
library(tseries)
library(corrplot)
library(quantmod)
library(forecast)
library(lubridate)
library(tidyverse)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3)
datasets.url <- "https://drive.usercontent.google.com/download?id=1BqKbN3FEqNcRXeisOPxR_LB8VcSCh7mE&export=download&authuser=0&confirm=t"
df <- read.csv(datasets.url)
df$Date <- as.Date(df$Date)
str(df)
# Checking for missing values
sum(is.na(df))
# Making GICS code as a factor variable
df$GICS <- as.factor(df$GICS)
# Removing the adjusted column as it is not required for our analysis
newdf <- df %>% select(-c("Adj.Close")) %>%
arrange(Date) %>% # sorting the data by date
mutate(daily_returns = (Close - lag(Close)) / lag(Close))
# remove first row to avoid NA values
newdf <- newdf[-1,]
head(newdf)
str(newdf)
industry_counts <- df %>%
distinct(Symbol, GICS) %>%
count(GICS)
ggplot(industry_counts, aes(x = GICS, y = n)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Number of Companies per Industry", x = "Industry (GICS)", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(df, aes(x = year(df$Date), fill = GICS)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(newdf, aes(x = year(newdf$Date), y = Volume, fill = GICS)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
df <- data.frame(read.csv("https://raw.githubusercontent.com/DATS6101-TeamNeo/datasets/main/dataset2003-2023.csv"))
str(df)
summary(df)
work_df <- subset(df, select = -(6))
work_df$daily_change <- (work_df$Close - lag(work_df$Close)) / lag(work_df$Close) * 100
head(work_df)
work_df <- na.omit(work_df)
head(work_df)
# TODO:
adf.test(work_df$Close)
# Check the stationarity using the ACF and PACF plots.
acf(work_df$Close, main = "ACF Plot")
pacf(work_df$Close, main = "PACF Plot")
ts_data <- xts(work_df$Close, order.by = as.Date(work_df$Date))
# TODO:n
adf.test(ts_data)
diff_ts_data <- diff(ts_data, differences = 1)
diff_ts_data <- na.omit(diff_ts_data)
# TODO:
adf.test(diff_ts_data)
# TODO:
acf(diff_ts_data, main = "ACF Plot")
pacf(diff_ts_data, main = "PACF Plot")
work_df <- data.frame(subset(df, select = c(1, 5)))
# Feature selection (Example: using lagged values as features)
for (i in 1:7) {
work_df[[paste0('lag', i)]] <- lag(work_df$Close, i)
}
work_df <- na.omit(work_df)
# Split data into train and test sets
train_size <- 0.98
train_index <- round(nrow(work_df) * train_size)
train_data <- work_df[1:train_index, ]
test_data <- work_df[(train_index + 1):nrow(work_df), ]
# Train the linear regression model
lm_model <- lm(Close ~ lag1 + lag2 + lag3 + lag4 + lag5 + lag6 + lag7, data = train_data)
future_data <- test_data
future_data[, 3:ncol(future_data)] <- 0
future_data[1, 3:ncol(future_data)] <- rev(tail(train_data$Close, 7))
# Make predictions on test data
for (i in 1:nrow(future_data)) {
future_data$Close[i] <- predict(lm_model, newdata = future_data[i, ])
if (i < nrow(future_data)){
future_data[i + 1, 3:ncol(future_data)] <- c(future_data$Close[i], future_data[i, 3:(ncol(future_data) - 1)])
}
}
predictions <- future_data$Close
# Evaluate the model
errors <- predictions - test_data$Close
mae <- mean(abs(errors))
mse <- mean(errors^2)
rmse <- sqrt(mse)
# Print evaluation metrics
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
train_df <- data.frame(Date = work_df[1:train_index, "Date"], Value = coredata(work_df[1:train_index, "Close"]), Type = "Train data")
test_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(work_df[(train_index+1):nrow(work_df), "Close"]), Type = "Test data")
forecast_df <- data.frame(Date = work_df[(train_index+1):nrow(work_df), "Date"], Value = coredata(predictions), Type = "Forecast")
# Combine the data frames
combined_df <- rbind(train_df[train_df$Date > plot_start_date, ], test_df, forecast_df)
# Create the plot
ggplot(combined_df, aes(x = Date, y = Value, color = Type, linetype = Type)) +
geom_line() +
labs(title = "Train, Test, and Forecast Data Plot",
x = "Date",
y = "Closing Price") +
scale_color_manual(values = c("red", "orange", "blue")) +
scale_linetype_manual(values = c("dashed", "solid", "solid")) +
theme_minimal() +
theme(legend.position = "right")
train_data <- head(diff_ts_data, n = round(0.98 * length(diff_ts_data)))
test_data <- diff_ts_data[-seq_along(train_data)]
arima_model <- auto.arima(train_data)
summary(arima_model)
forecasts <- forecast(arima_model, h = length(test_data))
# Convert the forecasts to the original scale.
last_train_date <- index(tail(train_data, 1))
last_observed_value <- ts_data[last_train_date]
actual_preds <- as.vector(last_observed_value) + cumsum(forecasts$mean)
actual_test <- as.vector(last_observed_value) + cumsum(test_data)
actual_preds <- xts(actual_preds, order.by = index(actual_test))
# Compute the forecasting errors
errors <- actual_preds - actual_test
# Calculate evaluation metrics
mae <- mean(abs(errors))
mse <- mean(errors^2)
rmse <- sqrt(mse)
plot(ts_data[index(ts_data) <= last_train_date], type = "l", xlab = "Time", ylab = "Index closing price", main = "Train Data")
plot(ts_data[index(ts_data) > last_train_date], type = "l", xlab = "Time", ylab = "Index closing price", main = "Test Data")
plot_start_date <- as.Date("2023-01-01")
actual_train <- ts_data[index(ts_data) > plot_start_date & index(ts_data) <= last_train_date]
# Convert the time series data to data frames
train_df <- data.frame(Date = index(actual_train), Value = coredata(actual_train), Type = "Train data")
test_df <- data.frame(Date = index(actual_test), Value = coredata(actual_test), Type = "Test data")
forecast_df <- data.frame(Date = index(actual_preds)[-1], Value = actual_preds[-1], Type = "Forecast")
# Combine the data frames
combined_df <- rbind(train_df, test_df, forecast_df)
# Create the plot
ggplot(combined_df, aes(x = Date, y = Value, color = Type, linetype = Type)) +
geom_line() +
labs(title = "Train, Test, and Forecast Data Plot",
x = "Date",
y = "Closing Price") +
scale_color_manual(values = c("red", "orange", "blue")) +
scale_linetype_manual(values = c("dashed", "solid", "solid")) +
theme_minimal() +
theme(legend.position = "right")
as.Date("2024-04-24") + 1
as.Date("2024-04-24") + 2
as.Date("2024-04-24") + 7
# Should be clear with these dates.
great_rec_start <- as.Date("2008-09-15")
great_rec_end <- as.Date("2009-06-30")
covid_start <- as.Date("2020-02-03")
covid_end <- as.Date("2022-01-01") # *****
russ_uk_start <- as.Date("2022-02-24")
russ_uk_end <- as.Date("2024-02-24")
test_period <- 60
gr_train_data <- work_df[work_df$Date >= great_rec_start & work_df$Date <= great_rec_end, ]
gr_test_data <- work_df[work_df$Date > great_rec_end & work_df$Date <= great_rec_end+test_period, ]
gr_test_data
gr_train_data <- work_df[work_df$Date >= great_rec_start & work_df$Date <= great_rec_end, ]
gr_test_data <- work_df[work_df$Date > great_rec_end & work_df$Date <= great_rec_end+test_period, ]
covid_train_data <- work_df[work_df$Date >= covid_start & work_df$Date <= covid_end, ]
covid_test_data <- work_df[work_df$Date > covid_end & work_df$Date <= covid_end+test_period, ]
russ_uk_train_data <- work_df[work_df$Date >= russ_uk_start & work_df$Date <= russ_uk_end, ]
russ_uk_test_data <- work_df[work_df$Date > russ_uk_end & work_df$Date <= russ_uk_end+test_period, ]
head(gr_train_data)
head(gr_test_data)
rbind(gr_train_data, covid_train_data)
# Remove if unnecessary.
#test_period <- 30
train_offset <- 30
test_offset <- 30
gr_train_data <- work_df[work_df$Date >= (great_rec_start - train_offset) & work_df$Date <= (great_rec_end+test_offset), ]
#gr_test_data <- work_df[work_df$Date > great_rec_end & work_df$Date <= great_rec_end+test_period, ]
covid_train_data <- work_df[work_df$Date >= (covid_start - train_offset) & work_df$Date <= (covid_end+test_offset), ]
#covid_test_data <- work_df[work_df$Date > covid_end & work_df$Date <= covid_end+test_period, ]
russ_uk_train_data <- work_df[work_df$Date >= (russ_uk_start - train_offset) & work_df$Date <= (russ_uk_end), ]
#russ_uk_test_data <- work_df[work_df$Date > russ_uk_end & work_df$Date <= russ_uk_end+test_period, ]
train_data <- rbind(gr_train_data, covid_train_data, russ_uk_train_data)
head(train_data)
tail(train_data)
# Remove if unnecessary.
#test_period <- 30
train_offset <- 30
test_offset <- 30
gr_train_data <- work_df[work_df$Date >= (great_rec_start - train_offset) & work_df$Date <= (great_rec_end+test_offset), ]
#gr_test_data <- work_df[work_df$Date > great_rec_end & work_df$Date <= great_rec_end+test_period, ]
covid_train_data <- work_df[work_df$Date >= (covid_start - train_offset) & work_df$Date <= (covid_end+test_offset), ]
#covid_test_data <- work_df[work_df$Date > covid_end & work_df$Date <= covid_end+test_period, ]
russ_uk_train_data <- work_df[work_df$Date >= (russ_uk_start - train_offset) & work_df$Date <= (russ_uk_end), ]
#russ_uk_test_data <- work_df[work_df$Date > russ_uk_end & work_df$Date <= russ_uk_end+test_period, ]
train_data <- rbind(gr_train_data, covid_train_data, russ_uk_train_data)
test_data <- work_df[work_df$Date > russ_uk_end & work_df$Date <= russ_uk_end+test_offset, ]
head(train_data)
head(test_data)
work_df[work_df$Date > russ_uk_end & work_df$Date <= russ_uk_end+test_offset, ]
tail(work_df)
# Should be clear with these dates and what we'll be doing here.
great_rec_start <- as.Date("2008-09-15")
great_rec_end <- as.Date("2009-06-30")
covid_start <- as.Date("2020-02-03")
covid_end <- as.Date("2022-01-01") # *****
russ_uk_start <- as.Date("2022-02-24")
russ_uk_end <- as.Date("2023-10-24") # New dataset with 2024 data needed.
# Remove if unnecessary.
#test_period <- 30
train_offset <- 30
test_offset <- 30
gr_train_data <- work_df[work_df$Date >= (great_rec_start - train_offset) & work_df$Date <= (great_rec_end+test_offset), ]
#gr_test_data <- work_df[work_df$Date > great_rec_end & work_df$Date <= great_rec_end+test_period, ]
covid_train_data <- work_df[work_df$Date >= (covid_start - train_offset) & work_df$Date <= (covid_end+test_offset), ]
#covid_test_data <- work_df[work_df$Date > covid_end & work_df$Date <= covid_end+test_period, ]
russ_uk_train_data <- work_df[work_df$Date >= (russ_uk_start - train_offset) & work_df$Date <= (russ_uk_end), ]
#russ_uk_test_data <- work_df[work_df$Date > russ_uk_end & work_df$Date <= russ_uk_end+test_period, ]
train_data <- rbind(gr_train_data, covid_train_data, russ_uk_train_data)
test_data <- work_df[work_df$Date > russ_uk_end & work_df$Date <= russ_uk_end+test_offset, ]
tail(train_data)
head(test_data)
nrow(test_data)
# Split data into train and test sets
#train_size <- 0.98
#train_index <- round(nrow(work_df) * train_size)
#train_data <- work_df[1:train_index, ]
#test_data <- work_df[(train_index + 1):nrow(work_df), ]
# Train the linear regression model
lm_model <- lm(Close ~ lag1 + lag2 + lag3 + lag4 + lag5 + lag6 + lag7, data = train_data)
future_data <- test_data
future_data[, 3:ncol(future_data)] <- 0
future_data[1, 3:ncol(future_data)] <- rev(tail(train_data$Close, 7))
# Make predictions on test data
for (i in 1:nrow(future_data)) {
future_data$Close[i] <- predict(lm_model, newdata = future_data[i, ])
if (i < nrow(future_data)){
future_data[i + 1, 3:ncol(future_data)] <- c(future_data$Close[i], future_data[i, 3:(ncol(future_data) - 1)])
}
}
predictions <- future_data$Close
# Evaluate the model
errors <- predictions - test_data$Close
mae <- mean(abs(errors))
mse <- mean(errors^2)
rmse <- sqrt(mse)
# Print evaluation metrics
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
ts_data_train <- xts(train_data$Close, order.by = as.Date(work_df$Date))
ts_data_train <- xts(train_data$Close, order.by = as.Date(train_data$Date))
adf.test(ts_data_train)
diff_ts_data_train <- diff(ts_data_train, differences = 1)
diff_ts_data_train <- na.omit(diff_ts_data_train)
adf.test(ts_data_train)
diff_ts_data_train <- diff(ts_data_train, differences = 1)
diff_ts_data_train <- na.omit(diff_ts_data_train)
adf.test(diff_ts_data_train)
diff_ts_data_train
tail(diff_ts_data_train, 1)
arima_model <- auto.arima(diff_ts_data_train)
head(diff_ts_data_train)
is.na(diff_ts_data_train)
sum(is.na(diff_ts_data_train))
acf(diff_ts_data_train, main = "ACF Plot")
ts_data_train <- xts(train_data$Close, order.by = as.Date(train_data$Date))
adf.test(ts_data_train)
diff_ts_data_train <- diff(ts_data_train, differences = 1)
diff_ts_data_train <- na.omit(diff_ts_data_train)
adf.test(diff_ts_data_train)
head(diff_ts_data_train)
tail(diff_ts_data_train)
sum(is.na(diff_ts_data_train))
acf(diff_ts_data, main = "ACF Plot")
pacf(diff_ts_data, main = "PACF Plot")
acf(diff_ts_data_train, main = "ACF Plot")
diff_ts_data_train <- diff(ts_data_train, differences = 1)
sum(is.na(diff_ts_data_train))
train_data[gr_train_data$Date]
train_data[gr_train_data$Date, ]
